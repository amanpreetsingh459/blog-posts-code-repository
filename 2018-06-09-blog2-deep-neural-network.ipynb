{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This notebook contains for the code for <a href=\"https://amanpreetsingh459.github.io/2018/06/09/blog2-deep-neural-network.html\" target=\"_blank\">this</a> blog-post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Input array\n",
    "X=np.array([[1,0,1,0],[1,0,1,1],[0,1,0,1]])\n",
    "\n",
    "#Output\n",
    "y=np.array([[1],[1],[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "[2]\n",
      "[[2]]\n"
     ]
    }
   ],
   "source": [
    "print(np.sum(y))\n",
    "print(np.sum(y, axis = 0))\n",
    "print(np.sum(y, axis = 0, keepdims=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 4)\n",
      "(3, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Sigmoid Function\n",
    "def sigmoid (x):\n",
    "    return 1/(1 + np.exp(-x))\n",
    "\n",
    "#Derivative of Sigmoid Function\n",
    "def sigmoid_derivatives(x):\n",
    "    return x * (1 - x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Variable initialization\n",
    "epoch=10001 #Setting training iterations\n",
    "learning_rate=0.1 #Setting learning rate\n",
    "inputlayer_neurons = X.shape[1] #number of features in data set\n",
    "hiddenlayer1_neurons = 5 #number of 1st hidden layer's neurons\n",
    "hiddenlayer2_neurons = 5 #number of 2nd hidden layer's neurons\n",
    "output_neurons = 1 #number of neurons at output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#weight and bias initialization\n",
    "weights_input_to_hidden1 = np.random.normal(size=(inputlayer_neurons,hiddenlayer1_neurons))\n",
    "bias_input_to_hidden1 =np.random.normal(size=(1,hiddenlayer1_neurons))\n",
    "\n",
    "weights_hidden1_to_hidden2 = np.random.normal(size=(hiddenlayer1_neurons, hiddenlayer2_neurons))\n",
    "bias_hidden1_to_hidden2 =np.random.normal(size=(1,hiddenlayer2_neurons))\n",
    "\n",
    "weights_hidden2_to_output = np.random.normal(size=(hiddenlayer2_neurons,output_neurons))\n",
    "bias_hidden2_to_output=np.random.normal(size=(1,output_neurons))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.80831494926\n",
      "-12.1964091106\n",
      "-4.6507139537\n",
      "-0.691616944068\n",
      "5.58110257009\n",
      "1.04814751225\n"
     ]
    }
   ],
   "source": [
    "#Initial weights and biases\n",
    "print(np.sum(weights_input_to_hidden1))\n",
    "print(np.sum(weights_hidden1_to_hidden2))\n",
    "print(np.sum(weights_hidden2_to_output))\n",
    "\n",
    "print(np.sum(bias_input_to_hidden1))\n",
    "print(np.sum(bias_hidden1_to_hidden2))\n",
    "print(np.sum(bias_hidden2_to_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 5)\n",
      "(5, 5)\n",
      "(5, 1)\n",
      "(1, 5)\n",
      "(1, 5)\n",
      "(1, 1)\n"
     ]
    }
   ],
   "source": [
    "print(weights_input_to_hidden1.shape)\n",
    "print(weights_hidden1_to_hidden2.shape)\n",
    "print(weights_hidden2_to_output.shape)\n",
    "\n",
    "print(bias_input_to_hidden1.shape)\n",
    "print(bias_hidden1_to_hidden2.shape)\n",
    "print(bias_hidden2_to_output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Below is the graphical representation of our neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"imgcap\">\n",
    "<img src=\"/_images/blog2_neural_network_image.jpg\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the simplicity in the picture i have not added all the links from one layer to another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error after 1000.0 steps of training: 0.05018205356841837\n",
      "error after 2000.0 steps of training: 0.033859263420156945\n",
      "error after 3000.0 steps of training: 0.027105713020409337\n",
      "error after 4000.0 steps of training: 0.023207920712687027\n",
      "error after 5000.0 steps of training: 0.02060028777010732\n",
      "error after 6000.0 steps of training: 0.01870175568700289\n",
      "error after 7000.0 steps of training: 0.0172412749291508\n",
      "error after 8000.0 steps of training: 0.016073402728554335\n",
      "error after 9000.0 steps of training: 0.015112271171374977\n",
      "error after 10000.0 steps of training: 0.014303526532159678\n"
     ]
    }
   ],
   "source": [
    "for i in range(epoch):\n",
    "    #Forward Propogation\n",
    "    hidden_layer1_activations = sigmoid(np.dot(X, weights_input_to_hidden1) + bias_input_to_hidden1)\n",
    "    hidden_layer2_activations = sigmoid(np.dot(hidden_layer1_activations, weights_hidden1_to_hidden2) + bias_hidden1_to_hidden2)\n",
    "    output_layer_activations = sigmoid(np.dot(hidden_layer2_activations, weights_hidden2_to_output) + bias_hidden2_to_output)\n",
    "\n",
    "    #Backpropagation\n",
    "    \n",
    "    #getting the error contribution by each layer    \n",
    "    #output to hidden2\n",
    "    error_output_layer = y - output_layer_activations\n",
    "    slope_output_layer = sigmoid_derivatives(output_layer_activations)\n",
    "    delta_output_layer = error_output_layer * slope_output_layer    \n",
    "    \n",
    "    #hidden2 to hidden1\n",
    "    slope_hidden_layer2 = sigmoid_derivatives(hidden_layer2_activations)    \n",
    "    error_hidden_layer2 = delta_output_layer.dot(weights_hidden2_to_output.T)\n",
    "    delta_hidden_layer2 = error_hidden_layer2 * slope_hidden_layer2    \n",
    "    \n",
    "    #hidden1 to input\n",
    "    slope_hidden_layer1 = sigmoid_derivatives(hidden_layer1_activations)\n",
    "    error_hidden_layer1 = delta_hidden_layer2.dot(weights_hidden1_to_hidden2.T)\n",
    "    delta_hidden_layer1 = error_hidden_layer1 * slope_hidden_layer1\n",
    "    \n",
    "    #weight and bias adjustments \n",
    "    #output to hidden2\n",
    "    weights_hidden2_to_output += hidden_layer2_activations.T.dot(delta_output_layer) * learning_rate\n",
    "    bias_hidden2_to_output += np.sum(delta_output_layer, axis=0, keepdims=True) * learning_rate\n",
    "    \n",
    "    #hidden2 to hidden1\n",
    "    weights_hidden1_to_hidden2 += hidden_layer1_activations.T.dot(delta_hidden_layer2) * learning_rate\n",
    "    bias_hidden1_to_hidden2 += np.sum(delta_hidden_layer2, axis=0, keepdims=True) * learning_rate        \n",
    "    \n",
    "    #hidden1 to input\n",
    "    weights_input_to_hidden1 += X.T.dot(delta_hidden_layer1) * learning_rate    \n",
    "    bias_input_to_hidden1 += np.sum(delta_hidden_layer1, axis=0, keepdims=True) * True\n",
    "    \n",
    "    if i != 0 and i % 1000 == 0:\n",
    "        print(\"error after {0} steps of training: {1}\".format((i/1000*1000),np.sum(error_output_layer)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see that after every 1000 iterations the error is coming down. That is what the learning is. Below are the changes in the weights from start till last iteration and the outputs actual and learnt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 5)\n",
      "(3, 5)\n",
      "(3, 1)\n"
     ]
    }
   ],
   "source": [
    "print(hidden_layer1_activations.shape)\n",
    "print(hidden_layer2_activations.shape)\n",
    "print(output_layer_activations.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.734876899466\n",
      "-19.7401244794\n",
      "-8.00361029621\n",
      "-1.59045636135\n",
      "6.57927464733\n",
      "2.33363090766\n"
     ]
    }
   ],
   "source": [
    "#Learnt weights and biases\n",
    "print(np.sum(weights_input_to_hidden1))\n",
    "print(np.sum(weights_hidden1_to_hidden2))\n",
    "print(np.sum(weights_hidden2_to_output))\n",
    "\n",
    "print(np.sum(bias_input_to_hidden1))\n",
    "print(np.sum(bias_hidden1_to_hidden2))\n",
    "print(np.sum(bias_hidden2_to_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1]\n",
      " [1]\n",
      " [0]]\n",
      "[[ 0.98575188]\n",
      " [ 0.980885  ]\n",
      " [ 0.0190596 ]]\n"
     ]
    }
   ],
   "source": [
    "print(y)\n",
    "print(output_layer_activations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
